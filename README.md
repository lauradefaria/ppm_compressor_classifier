<a href='https://isocpp.org/' target="_blank"><img alt='C++' src='https://img.shields.io/badge/C++-100000?style=for-the-badge&logo=c%2B%2B&logoColor=white&labelColor=00599C&color=00599C'/></a>
<a href='https://gcc.gnu.org/' target="_blank"><img alt='GCC' src='https://img.shields.io/badge/GCC-100000?style=for-the-badge&logo=gnu&logoColor=white&labelColor=A42E2B&color=A42E2B'/></a>
<a href='https://www.python.org/' target="_blank"><img alt='Python' src='https://img.shields.io/badge/Python-100000?style=for-the-badge&logo=python&logoColor=white&labelColor=3776AB&color=3776AB'/></a>
<a href='https://jupyter.org/' target="_blank"><img alt='Jupyter' src='https://img.shields.io/badge/Jupyter-100000?style=for-the-badge&logo=jupyter&logoColor=white&labelColor=F37626&color=F37626'/></a>
<a href='https://pandas.pydata.org/' target="_blank"><img alt='Pandas' src='https://img.shields.io/badge/Pandas-100000?style=for-the-badge&logo=pandas&logoColor=white&labelColor=150458&color=150458'/></a>
<a href='https://numpy.org/' target="_blank"><img alt='NumPy' src='https://img.shields.io/badge/NumPy-100000?style=for-the-badge&logo=numpy&logoColor=white&labelColor=013243&color=013243'/></a>
<a href='https://scikit-learn.org/' target="_blank"><img alt='scikit-learn' src='https://img.shields.io/badge/scikit--learn-100000?style=for-the-badge&logo=scikit-learn&logoColor=white&labelColor=F7931E&color=F7931E'/></a>
<a href='https://huggingface.co/' target="_blank"><img alt='HuggingFace' src='https://img.shields.io/badge/HuggingFace-100000?style=for-the-badge&logo=huggingface&logoColor=white&labelColor=FFD21E&color=FFD21E'/></a>
<a href='https://code.visualstudio.com/' target="_blank"><img alt='VS Code' src='https://img.shields.io/badge/VS_Code-100000?style=for-the-badge&logo=visual-studio-code&logoColor=white&labelColor=007ACC&color=007ACC'/></a>
<a href='https://www.reddit.com/' target="_blank"><img alt='Reddit' src='https://img.shields.io/badge/Reddit-100000?style=for-the-badge&logo=reddit&logoColor=white&labelColor=FF4500&color=FF4500'/></a>
</div>

# Projeto da implementaÃ§Ã£o de um PPM-C

ImplementaÃ§Ã£o completa do algoritmo **PPM-C (Prediction by Partial Matching)** desenvolvido para a disciplina de IntroduÃ§Ã£o Ã  Teoria da InformaÃ§Ã£o  na UFPB. O projeto apresenta duas aplicaÃ§Ãµes principais:

### Compressor-Descompressor
Sistema de compressÃ£o de dados usando PPM-C com codificaÃ§Ã£o aritmÃ©tica de 32 bits e Ã¡rvore Patricia para gerenciamento eficiente de contextos. Testado no Corpus Silesia, alcanÃ§ando resultados competitivos com compressores comerciais como WinRAR e 7zip.

### Classificador de SaÃºde Mental
AplicaÃ§Ã£o inovadora do mÃ©todo PPM para identificaÃ§Ã£o de condiÃ§Ãµes de saÃºde mental a partir de textos do Reddit. O sistema analisa padrÃµes linguÃ­sticos para classificar 6 categorias: ansiedade, depressÃ£o, bipolar, estresse, transtorno de personalidade e tendÃªncias suicidas.

---

## ğŸ“‚ Estrutura do Projeto
```
.
â”œâ”€â”€ src/                      # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ main.cpp             # Ponto de entrada do programa
â”‚   â””â”€â”€ ReadData.cpp         # Leitura de arquivos
â”œâ”€â”€ ppm/                      # ImplementaÃ§Ã£o da Ãrvore Patricia
â”œâ”€â”€ arithmetic/               # Codificador AritmÃ©tico
â”œâ”€â”€ gf/                       # FunÃ§Ãµes de encode/decode
â”œâ”€â”€ PreProcessing/            # Scripts de prÃ©-processamento
â”‚   â””â”€â”€ HuggingFace.ipynb    # Pipeline de classificaÃ§Ã£o
â”œâ”€â”€ matrizConfusao/           # Matrizes de confusÃ£o (K=0 a K=6)
â”œâ”€â”€ modelos.zip              # Modelos treinados para classificaÃ§Ã£o
â”œâ”€â”€ resultados_k*.txt        # Resultados de validaÃ§Ã£o
â”œâ”€â”€ comandoParaRodarPPM      # Exemplo de uso do compressor
â”œâ”€â”€ Makefile                 # AutomaÃ§Ã£o de compilaÃ§Ã£o
â””â”€â”€ README.md
```

---

## ğŸŒ³ Ãrvore Patricia no PPM-C

A *Patricia tree* (ou *trie comprimida*) Ã© uma variaÃ§Ã£o da Ã¡rvore trie usada para armazenar strings (ou sequÃªncias de sÃ­mbolos) de forma mais compacta.

Em uma trie â€œpuraâ€, cada aresta corresponde a um Ãºnico caractere. Isso gera Ã¡rvores muito grandes, especialmente se houver poucos dados em comum entre as palavras. Na Patricia tree, vÃ¡rias arestas consecutivas sem bifurcaÃ§Ã£o sÃ£o comprimidas em uma Ãºnica aresta que guarda um prefixo inteiro.

**Destaques:**
- Alfabeto completo de bytes (0-255)
- Suporte para K_max variÃ¡vel (testado de 0 a 6)
- Melhor resultado: 0.881 bits/sÃ­mbolo (arquivo XML, K=6)

### Por que Patricia Tree?

O PPM-C necessita:
1. Manter **tabelas de contexto** com frequÃªncias de sÃ­mbolos
2. **Busca rÃ¡pida** de contextos jÃ¡ observados
3. **Economia de memÃ³ria** para milhares de contextos

A Patricia tree resolve isso atravÃ©s de:
- **CompressÃ£o**: Prefixos comuns compartilhados em nÃ³s Ãºnicos
- **EficiÃªncia**: InserÃ§Ã£o e busca em O(|k|)
- **Adaptabilidade**: Cresce dinamicamente conforme novos contextos aparecem

### Exemplo Visual

Palavras: `casa`, `caso`, `canto`

**Trie Normal:**
```
c â†’ a â†’ s â†’ a
    â†“
    s â†’ o
    â†“
    n â†’ t â†’ o
```

**Patricia Tree:**
```
c â†’ a â†’ s â†’ [a, o]
    â†“
    n â†’ to
```

---

### Vantagem da Patricia Tree nesse cenÃ¡rio

* **Compacta**: evita desperdiÃ§ar memÃ³ria repetindo cadeias longas sem bifurcaÃ§Ãµes.
* **Adaptativa**: cresce conforme novos contextos sÃ£o vistos.
* **Eficiente**: busca/inserÃ§Ã£o sÃ£o rÃ¡pidas, essenciais para compressÃ£o.
* **FlexÃ­vel**: cada nÃ³ jÃ¡ armazena frequÃªncias, nÃºmero de sÃ­mbolos distintos e atÃ© o sÃ­mbolo especial ESC (*escape*), usado quando o sÃ­mbolo nÃ£o foi visto no contexto.

Exemplo grafico da Ãrvore Patricia:

<img src="https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwithfern.com%2Fhttps%3A%2F%2Falchemy.docs.buildwithfern.com%2Fdocs%2F2025-08-30T01%3A44%3A18.308Z%2Ftutorials%2Falchemy-university%2Fcryptography-basics%2F1920px-Patricia_trie.svg-1-.png&w=1920&q=75" 
     alt="Ãrvore Redimensionada" width="50%">

Resumindo:
A Ã¡rvore Patricia serve no PPM-C como uma **estrutura compacta e eficiente para armazenar e acessar as tabelas de contexto**, permitindo inserir novos contextos, atualizar frequÃªncias e buscar probabilidades para a compressÃ£o e descompressÃ£o.

---

## ğŸ§  Sistema de ClassificaÃ§Ã£o

### Base de Dados
- **Fonte**: HuggingFace (textos do Reddit)
- **Total**: 87.396 amostras apÃ³s prÃ©-processamento
- **DivisÃ£o**: 60% treino, 20% validaÃ§Ã£o, 20% teste

### Metodologia
1. **Treinamento**: PPM adaptativo para cada classe
2. **ValidaÃ§Ã£o**: Teste de K=0 a K=6 para seleÃ§Ã£o do melhor modelo
3. **Teste**: AvaliaÃ§Ã£o final com mÃ©tricas detalhadas

### Resultados por K

| K | AcurÃ¡cia | ObservaÃ§Ã£o |
|---|----------|------------|
| 0 | 41.4% | Ordem zero (frequÃªncias globais) |
| 3 | 79.5% | EstabilizaÃ§Ã£o inicial |
| **6** | **81.2%** | **Melhor resultado** |

### Matrizes de ConfusÃ£o

O diretÃ³rio `matrizConfusao/` contÃ©m visualizaÃ§Ãµes completas do desempenho do classificador para cada valor de K, demonstrando a evoluÃ§Ã£o da precisÃ£o e os padrÃµes de confusÃ£o entre classes.

**AnÃ¡lise**: A confusÃ£o mais comum ocorre entre DepressÃ£o â†” SuicÃ­dio, devido Ã  sobreposiÃ§Ã£o semÃ¢ntica natural entre essas condiÃ§Ãµes.

**Resultados:**
- **AcurÃ¡cia: 81.2%** (K=6)
- Base: 87.396 textos processados
- Melhor classe: Transtorno de Personalidade (F1-Score: 0.957)

--- 

## ğŸ’» ExecuÃ§Ã£o Local

### PrÃ©-requisitos
Para o Compressor (C++)

- Compilador: GCC 9.0+ ou compatÃ­vel com C++17
Sistema Operacional:
- Windows 10/11
Linux (Ubuntu 22.04+ recomendado)
- MemÃ³ria RAM: MÃ­nimo 8GB (16GB recomendado para K > 3)

Para o Classificador (Python)

- Python: 3.8 ou superior
- Jupyter Notebook: Ãšltima versÃ£o
- Bibliotecas Python: pandas, numpy, scikit-learn, matplotlib, seaborn

### CompilaÃ§Ã£o: Manualmente

#### WINDOWS:  
```bash
g++ -std=c++17 -Wall -Wextra src/main.cpp src/ReadData.cpp ppm/PatriciaTree.cpp gf/generalFunctions.cpp arithmetic/ArithmeticCoder.cpp arithmetic/BitIoStream.cpp arithmetic/FrequencyTable.cpp -I. -I./src -I./ppm -I./gf -I./arithmetic -o main.exe
```

#### LINUX: 
```bash
g++ -std=c++17 -Wall -Wextra src/main.cpp ppm/PatriciaTree.cpp -I. -I./src -I./ppm -o main
```

#### CompilaÃ§Ã£o: MakeFile
```bash
make
./main seu_arquivo_entrada.txt
```

### Passos
1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/lauradefaria/Teoria_da_Informacao.git
   ```
2. Realize o processo de `CompilaÃ§Ã£o` por meio do MakeFile ou manualmente *(verifique o comando acima)*
3. Execute com o comando:
   ```bash
   ./main seu_arquivo_entrada.txt
   ```
4. Para utilizar o classificador de saÃºde mental
   ```bash
   pip install datasets pandas numpy scikit-learn matplotlib seaborn jupyter
   ```
5. No notebook `PreProcessing/HuggingFace` execute as cÃ©lulas sequencialmente.
6. Execute os notebooks da pasta `matrizConfusao/`

---

## ğŸ“– Autores 

| [<img loading="lazy" src="https://avatars.githubusercontent.com/u/45434515?v=4" width=115><br><sub>Laura de Faria</sub>](https://github.com/lauradefaria) | [<img loading="lazy" src="https://avatars.githubusercontent.com/u/72822997?v=4" width=115><br><sub>Renata Mendes</sub>](https://github.com/renatamendesc) | [<img loading="lazy" src="https://avatars.githubusercontent.com/u/64603683?v=4" width=115><br><sub>Rodrigo Pereira</sub>](https://github.com/Rodrigo-P-Nascimento) |
| :---: | :---: | :---: |

---

## ğŸ“„ License

[![License](http://img.shields.io/:license-mit-blue.svg?style=flat-square)](http://badges.mit-license.org)

- **[MIT license](http://opensource.org/licenses/mit-license.php)**

---

## ğŸ“š ReferÃªncias

1. CLEARY, John; WITTEN, Ian. Data Compression Using Adaptive Coding and Partial String Matching. IEEE Transactions on Communications, 1984.

2. NAYUKI. [Reference Arithmetic Coding](https://github.com/nayuki/Reference-arithmetic-coding). GitHub, 2025.

3. SALOMON, David. Data Compression: The Complete Reference. 3Âª ed. Springer, 2004.
